{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- <img src=\"pics/CFDS.png\" width=75px>-->\n",
    "<img src=\"../pics/DVFA-Akademie_Logo_800px.jpg\" width=300px>\n",
    "<br>\n",
    "    <p style=\"color:#0E1E5E\">\n",
    "    <b>\n",
    "        <font size=\"6\">CFDS® – Chartered Financial Data Scientist</font>\n",
    "        <br><br>\n",
    "        <font size=\"8\">Statistics with Python</font>\n",
    "    </b>\n",
    "<br><br>\n",
    "<b>\n",
    "    <font size=\"5\"> \n",
    "        Prof. Dr. Natalie Packham <br><br>\n",
    "        December 2022\n",
    "    </font>\n",
    "</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Packages-for-statistics\" data-toc-modified-id=\"Packages-for-statistics-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Packages for statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#numpy\" data-toc-modified-id=\"numpy-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>numpy</code></a></span></li><li><span><a href=\"#scipy\" data-toc-modified-id=\"scipy-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>scipy</code></a></span></li><li><span><a href=\"#statsmodels\" data-toc-modified-id=\"statsmodels-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>statsmodels</code></a></span></li><li><span><a href=\"#pandas\" data-toc-modified-id=\"pandas-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>pandas</code></a></span></li><li><span><a href=\"#seaborn\" data-toc-modified-id=\"seaborn-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>seaborn</code></a></span></li></ul></li><li><span><a href=\"#Descriptive-Statistics-+-Statistical-Plots-in-Python\" data-toc-modified-id=\"Descriptive-Statistics-+-Statistical-Plots-in-Python-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Descriptive Statistics + Statistical Plots in Python</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-and-merging-data-into-one-pandas.DataFrame\" data-toc-modified-id=\"Reading-and-merging-data-into-one-pandas.DataFrame-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Reading and merging data into one <code>pandas.DataFrame</code></a></span></li><li><span><a href=\"#Plotting-the-data\" data-toc-modified-id=\"Plotting-the-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Plotting the data</a></span></li><li><span><a href=\"#Descriptive-statistics\" data-toc-modified-id=\"Descriptive-statistics-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Descriptive statistics</a></span></li></ul></li><li><span><a href=\"#Hypothesis-testing-in-Python\" data-toc-modified-id=\"Hypothesis-testing-in-Python-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hypothesis testing in Python</a></span></li><li><span><a href=\"#Regression-in-Python\" data-toc-modified-id=\"Regression-in-Python-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Regression in Python</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Packages for statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Main packages for probability distributions and statistics in Python: \n",
    "* ``numpy``: https://numpy.org/doc/stable/reference/routines.statistics.html\n",
    "* ``scipy``: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "* ``statsmodels``: https://www.statsmodels.org/stable/index.html\n",
    "* ``pandas``: https://pandas.pydata.org\n",
    "* ``seaborn``: https://seaborn.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ``numpy``\n",
    "\n",
    "* ``numpy`` has a number of functions for descriptive statistics, such as computing means and standard deviations as well as computing histograms. \n",
    "* The package ``numpy.random`` contains functions for generating random numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(123) # initiate random-number generator\n",
    "x = npr.normal(170, 15, 1000) # normal random numbers\n",
    "np.round([np.mean(x), np.std(x), np.quantile(x,0.05)],2) # some descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hist=np.histogram(x,bins=10,density=True) \n",
    "hist # relative frequencies and corresponding intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ``scipy``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``scipy`` provides implementations of many probability distributions, e.g. ``norm`` for the normal distribution. \n",
    "* Each probability distribution features the following methods:\n",
    "    * ``rvs``: generate random numbers\n",
    "    * ``pdf``: probability density function (continous distributions)\n",
    "    * ``pmf``: probability mass function (discrete distributions)\n",
    "    * ``cdf``: (cumulative) distribution function\n",
    "    * ``ppf``: quantile function (percent point function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* There are many other functions, e.g. for the mean, variance, median, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.norm.rvs(0,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm # this is an alternative to import just one distribution\n",
    "norm.rvs(0,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-4,4,0.05)\n",
    "plt.plot(x,norm.pdf(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20 # number of trials\n",
    "p=0.5 # probability\n",
    "k = np.arange(0,n)\n",
    "plt.bar(k,sps.binom.pmf(k,n,0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical methods\n",
    "* A number of descriptive statistics methods are available in ``scipy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = norm.rvs(0,1,100)\n",
    "sps.describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.relfreq(z) ## relative frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multivariate statistics methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate correlated random numbers\n",
    "rho = 0.3\n",
    "z1, z2=norm.rvs(0,1,(2,10000)) # two samples of independent random normals\n",
    "x = z1\n",
    "y = rho * z1 + np.sqrt(1-rho**2) * z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.pearsonr(x,y) # Correlation coefficient; second argument returns is the p-value for testing rho=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two-sided $t$-test on the sample mean.\n",
    "* Arguments are the sample and the expected value under $H_0$. \n",
    "* Returns values are the test statistic and the two-sided $p$-value.\n",
    "* Divide this by two to obtain the one-sided $p$-value (given the sample mean points in the direction of $H_1$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = norm.rvs(170, 15, 100)\n",
    "sps.ttest_1samp(x,165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distribution fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We fit the random numbers to a Student-$t$ distribution. \n",
    "* This returns the degrees-of-freedom parameter $\\nu$, mean and scale parameter. \n",
    "* The scale parameter is close to the standard deviation if $\\nu$ is large.\n",
    "* The Student-$t$ distribution converges to a normal distribution as $\\nu\\rightarrow\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.t.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ``statsmodels``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``statsmodels`` provides classes and functions for the estimation of different statistical models as well as statistical testing.\n",
    "* In particular, it is useful for fitting regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ``pandas``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``pandas`` is a library for data analysis. \n",
    "* It provides the classes ``DataFrame`` and ``Series`` that hold data. \n",
    "* Data in a ``DataFrame`` is organised as a table, whereas data in ``Series`` consists of one data sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ``seaborn``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``seaborn`` specialises in statistical data visualisation and integrates well with ``pandas``.\n",
    "<img src=\"../pics/function_overview_8_0.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Descriptive Statistics + Statistical Plots in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the following we consider SMI (Swiss Market Index) and EuroStoxx 50 stock indices. \n",
    "* Historical daily prices were downloaded from http://finance.yahoo.com with ticker symbols ``^SSMI`` and ``^STOXX50E``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reading and merging data into one ``pandas.DataFrame``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi = pd.read_csv(\"../data/^SSMI.csv\", index_col=0, parse_dates=True)\n",
    "stoxx = pd.read_csv(\"../data/^STOXX50E.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "smi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "stoxx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Join the data.\n",
    "* The argument `inner` chooses as index the intersection of both indices (i.e., indices that exist for both datasets). \n",
    "* The alternative argument `outer` would build the nex index as the union of both indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = smi.join(stoxx, how='inner', lsuffix='_smi', rsuffix='_stoxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Add returns of both data series to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"r_smi\"] = np.log(df[\"Adj Close_smi\"]/df[\"Adj Close_smi\"].shift())\n",
    "df[\"r_stoxx\"] = np.log(df[\"Adj Close_stoxx\"]/df[\"Adj Close_stoxx\"].shift())\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Adj Close_smi\",\"Adj Close_stoxx\"]].plot(figsize=(10,5), subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Both time series in one plot with separate axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "ax1 = ax0.twinx()\n",
    "\n",
    "p1=df[\"Adj Close_smi\"].plot(ax=ax0, label=\"SMI\")\n",
    "p2=df[\"Adj Close_stoxx\"].plot(ax=ax1, color='orange', label=\"EuroStoxx 50\")\n",
    "fig0.legend(bbox_to_anchor=(0.85,0.85))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"r_smi\", \"r_stoxx\"]].plot(figsize=(10, 5), subplots=True);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `kde` stands for __kernel density estimator__, which is a continuous estimate of the histogram.\n",
    "* This uses the `seaborn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sns.distplot(df[\"r_smi\"], kde=True,label=\"SMI\"),sns.distplot(df[\"r_stoxx\"], \\\n",
    "                                                              kde=True, label=\"EuroStoxx\", axlabel=\"return\")];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A scatter plot with univariate histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df, x=\"r_smi\", y=\"r_stoxx\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Histograms and scatterplots. \n",
    "* This is particularly useful if there are more than two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, vars=(\"r_smi\",\"r_stoxx\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Scatterplot with so-called __rug plots__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, x=\"r_smi\", y=\"r_stoxx\")\n",
    "sns.rugplot(df[\"r_smi\"], axis=\"x\")\n",
    "sns.rugplot(df[\"r_stoxx\"], axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``pandas`` has some built-in functionality for descriptive statistics. \n",
    "* These functions are sometimes called ``aggregate`` functions as they (generally) produce a lower-dimensional result (exceptions are ``cumsum`` and ``cumprod``). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ret = df[[\"r_smi\", \"r_stoxx\"]]\n",
    "type(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "[ret.mean(), ret.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ret.quantile(q=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Value-at-risk\n",
    "\n",
    "* __Value-at-risk (VaR)__ at the confidence level $\\alpha$ is a popular risk measure that expresses the loss level that is exceeded only with a given probability $1-\\alpha$. \n",
    "* In other words, the daily loss is bounded by VaR with a probability of $\\alpha$. \n",
    "* In the example below, we calculate the 1-day VaR at the level $\\alpha=99\\%$ using the method of __historical simulation__.\n",
    "* The historical returns are taken as \"simulation\" scenarios. \n",
    "* The return scenario at the $1-\\alpha=1\\%$-quantile is applied to the current index price to express the index level that is exceeded only with a proability of $1\\%$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_smi = -df[\"Adj Close_smi\"].iloc[0] * df[\"r_smi\"].quantile(q=0.01)\n",
    "VaR_smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Aggregate functions\n",
    "* The function `aggregate` allows to specify several functions to be applied to each column. \n",
    "* If the called functions expect arguments, so called __lambda functions__ can be used. \n",
    "* This refers to a short-hand notation for very short functions or for \"anonymous\" functions. \n",
    "* See e.g. https://www.w3schools.com/python/python_lambda.asp for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.aggregate([lambda x: x.quantile(q=0.01), lambda x : x.quantile(q=0.05)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The libraries `numpy` and `scipy` also contain a plethora of functions for describing a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis testing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A number of hypothesis tests -- both parametric and non-parametric are provided in `scipy.stats`. \n",
    "* See https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests for a list of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The Jarque-Bera test tests if the given data is normally distribution by calculating a test statistic based on the skewness and kurtosis of the data.\n",
    "* The null hypothesis is that the data are from a normal distribution.\n",
    "* It returns the test statistic and the $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.jarque_bera(ret[\"r_smi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obviously, the SMI return data is not normally distributed. \n",
    "* Note the scientific notation: `4.282e-07`$=4.282 \\cdot 10^{-7}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Testing a trading strategy\n",
    "* In this example, we devise a very simple trading strategy that goes long if the previous day's return is positive and short otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"signal\" in df: # check if colummn exists\n",
    "    df.drop(columns=(\"signal\"))\n",
    "df[\"signal\"]= np.sign(ret[\"r_stoxx\"]).shift(1) # add column with the trading signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"r_stoxx\", \"signal\"]].tail() # check that the strategy is long if  \n",
    "                                 # the previous day's return was positive and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Add returns generated from strategy to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"r_strategy\" in df:\n",
    "    df.drop(columns=(\"r_strategy\"))\n",
    "df[\"r_strategy\"] = df[\"signal\"] * df[\"r_stoxx\"]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"r_stoxx\", \"r_strategy\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Now test $H_0: \\mu=0$ against $H_1:\\mu>0$, where $\\mu$ refers to the expected return of the strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"r_strategy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sp.stats.ttest_1samp(df[\"r_strategy\"], 0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-sided $p$-value translates into a one-sided $p$-value of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pvalue/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Let's test if the strategy performs better than a buy-and-hold strategy in the index (a popular benchmark / alternative strategy): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"r_strategy\"]-df[\"r_stoxx\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sp.stats.ttest_1samp((df[\"r_strategy\"]-df[\"r_stoxx\"]), 0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Testing against a random trading strategy\n",
    "* Another type of test on trading strategies tests if the strategy outperforms randomly generated trading signals with the same statistical properties -- i.e., the same number of long/short positions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* For this we generate 10,000 random permutations (re-orderings) of the trading signal and apply it to the time series of returns. \n",
    "* This generates an empirical distribution of a random trading strategy. \n",
    "* A $p$-value of the \"informed\" trading strategy is obtained as the relative frequency of observations achieving a greater return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "random_strategy = [(np.random.permutation(df[\"signal\"])*df[\"r_stoxx\"]).mean() \\\n",
    "                   for k in range(10000)]\n",
    "random_strategy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(random_strategy,color='orange',density=True)\n",
    "plt.plot([df[\"r_strategy\"].mean(),df[\"r_strategy\"].mean()], [0,400],color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[1 if random_strategy[k]>df[\"r_strategy\"].mean() else 0 for k in range(len(random_strategy))]\n",
    "np.sum(f)/len(random_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### OLS regression\n",
    "* __Linear regression__ captures the linear relationship between two variables. \n",
    "* For two variables $x,y$, we postulate a linear relationship: \n",
    "$$ y = \\alpha + \\beta x + \\varepsilon, \\quad \\alpha, \\beta\\in \\mathbb{R}.$$\n",
    "* Here, $\\alpha$ is the __intercept__, $\\beta$ is the __slope (coefficient)__ and $\\varepsilon$ is the __error term__. \n",
    "* Given  data sample of joint observations $(x_1,y_1), \\ldots, (x_n,y_n)$, we set \n",
    "$$ y_i = \\hat\\alpha + \\hat\\beta x_i + \\hat\\varepsilon_i,$$\n",
    "where $\\hat\\alpha$ and $\\hat\\beta$ are estimates of $\\alpha,\\beta$ and $\\hat\\varepsilon_1,\n",
    "\\ldots, \\hat\\varepsilon_n$ are the so-called __residuals__. \n",
    "* The __ordinary least squares (OLS)__ estimator $\\hat\\alpha,\\hat\\beta$ corresponds to those values of $\\alpha,\\beta$ that minimise the sum of squared residuals: \n",
    "$$\\min_{\\alpha,\\beta} \\sum_{i=1}^n \\varepsilon_i^2 = \\sum_{i=1}^n (y_i-\\alpha-\\beta x_i)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We use the package `statsmodels` to do linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "Y=ret[\"r_smi\"]\n",
    "X=ret[\"r_stoxx\"]\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results.predict()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $R$-syntax is also supported: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "results = smf.ols('r_smi ~ r_stoxx', data=ret).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### OLS regression: Interpretation of output and forecasting\n",
    "* The column `coef` lists the coefficients of the regression: the coefficient in the row labelled `const` corresponds to $\\hat\\alpha$ ($=0.0004$) and the coefficient in the row `r_stoxx` denotes $\\hat\\beta$ ($=0.5960$). \n",
    "* The estimated model in the example is thus: \n",
    "$$\n",
    "\\text{r_smi} = -0.0004 + 0.5960 \\text{ r_stoxx}. \n",
    "$$\n",
    "* The best forecast of the SMI return when observing an EuroStoxx 50 return of 2% is therefore $-0.0004 + 0.5960 \\cdot 0.02$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params[0] + results.params[1] * 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation: $R^2$\n",
    "* To __validate__ the model, i.e., to determine, if the model in itself and the explanatory variable(s) make sense, we look $R^2$ and various $p$-values (or confidence intervals or $t$-statistics). \n",
    "* $R^2$ measures the fraction of variance in the dependent variable $Y$ that is captured by the regression line; $1-R^2$ is the fraction of $Y$-variance that remains in the residuals $\\varepsilon_i^2$, $i=1,\\ldots, n$. \n",
    "* In the output above $R^2$ is given as $0.716$. In other words, $71.6\\%$ of the variance in SMI returns are \"explained\" by EuroStoxx returns. \n",
    "* A high $R^2$ (and this one is high) is necessary for making forecasts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation: $t$-statistic\n",
    "* The $t$-statistic corresponds to the __number of standard deviations__ that the estimated coefficient $\\hat\\beta$ is away from $0$ (the mean under $H_0$). \n",
    "* For a normal distribution, we have the following rules of thumb: \n",
    "    * $66\\%$ of observations lie within one standard deviation of the mean\n",
    "    * $95\\%$ of observations lie within two standard deviations of the mean\n",
    "    * $99.7\\%$ of observations lie within three standard deviations of the mean  \n",
    "<center>\n",
    "<img src=\"../pics/normal6.png\" width=400px>\n",
    "</center>\n",
    "* If the sample size is large enough, then the $t$-statistic is approximately normally distributed, and if it is large (in absolute terms), then this is an indication against $\\beta=0$. \n",
    "* In the example above, the $t$-statistics is 25.129, i.e., $\\hat\\beta$ is approx. 25 standard deviations away from zero, which is practically impossible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation: $p$-value\n",
    "* The $p$-value expresses the probability of observing a coefficient estimate as extreme (away from zero) as $\\hat\\beta$ under $H_0$, i.e., when $\\beta=0$. \n",
    "* In other words, it measures the probability of observing a $t$-statistic as extreme as the one observed if $\\beta=0$. \n",
    "* If the $p$-value (column ``P>|t|``) is smaller than the desired level of significance (typically 5%), then the $H_0$ can be rejected and we conclude that $\\beta\\not=0$. \n",
    "* In the example above, the $p$-value is given as $0.000$, i.e., it is so small, that we can conclude the estimated coefficient $\\hat\\beta$ is so extreme (= away from zero) that is virtually impossible to obtain such an estimated if $\\beta=0$. \n",
    "\n",
    "* Finally, the $F$-test tests the hypotheses $H_0:R^2=0$ versus $H_1:R^2\\not=0$. In a multiple regression with $k$ independent variables, this is equivalent to $H_0: \\beta_1=\\cdots=\\beta_k=0$. \n",
    "* In the example above, the $p$-value of the $F$-test is $0$, so we conclude that the model overall has explanatory power. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Seaborn provides a number of data sets to explore. A list is found here: \n",
    "\n",
    "https://github.com/mwaskom/seaborn-data\n",
    "\n",
    "Use the seaborn function `load_dataset` to load the `penguins` data. Amongst other things it contains the bill length (length of beak), bill depth, flipper length and body mass of penguins. \n",
    "\n",
    "Calculate the correlations of these observations and use the seaborn `heatmap` function to visualise the correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "penguins=sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "penguins[[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "penguins.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(penguins.corr())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
